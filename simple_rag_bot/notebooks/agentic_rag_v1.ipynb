{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This version adds on to the existing `simple_agentic_rag.ipynb` notebook. Major changes are,\n",
        "1. Improved rewrite logic. Rewriting happens at the beginning of the graph, instead of only for retreiver based questions.\n",
        "2. Addition of chit_chat module to handle simple chitchat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW9MwnF56b-0"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yPUUFMUKhdn",
        "outputId": "c04a8c36-8279-40e5-b267-8a045b402bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ratelimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\n",
            "langchain 0.3.23 requires langchain-core<1.0.0,>=0.3.51, but you have langchain-core 0.3.41 which is incompatible.\n",
            "langchain 0.3.23 requires langchain-text-splitters<1.0.0,>=0.3.8, but you have langchain-text-splitters 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q pymupdf==1.25.3 \\\n",
        "                ratelimit==2.2.1\\\n",
        "                langchain-text-splitters==0.3.6 \\\n",
        "                langchain-core==0.3.41\\\n",
        "                langgraph==0.3.5\\\n",
        "                langchain-google-genai==2.0.11 \\\n",
        "                pymilvus==2.5.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsC0SbfTezgE"
      },
      "source": [
        "#### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBTmiDr9LEcX",
        "outputId": "5f19a185-2b1a-42f3-f1c7-d4d6f8cfcd71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ognLVOY5hNv6"
      },
      "source": [
        "#### Initialize required variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5MHIuHwGku7"
      },
      "outputs": [],
      "source": [
        "GEMINI_API_KEY = \"YOUR-API-KEY\" #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9mf7yZrPLLpf"
      },
      "outputs": [],
      "source": [
        "# Path to folder containing rag pdfs\n",
        "rag_files_path = \"/content/drive/MyDrive/GenAI_Expts/rag_datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8cnpqRwL9860"
      },
      "outputs": [],
      "source": [
        "# Path to embeddings jsonl file (if created already), instead of chunking and creating embeddings all over again\n",
        "embeddings_path = \"/content/drive/MyDrive/GenAI_Expts/cleaned_embeddings.jsonl\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sI6D1D-e14m"
      },
      "source": [
        "#### Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7jhzpyj-LvJS"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import fitz\n",
        "import json\n",
        "import time\n",
        "import uuid\n",
        "from tqdm import tqdm\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from ratelimit import limits, sleep_and_retry\n",
        "from typing import List, Annotated, Sequence\n",
        "from typing_extensions import TypedDict, Annotated\n",
        "from IPython.display import display, Markdown, Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Fbs4RM83QPnA"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.tools import tool, InjectedToolArg\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain_core.messages.base import messages_to_dict\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "from pymilvus import MilvusClient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8C0jrH5fJPA"
      },
      "source": [
        "#### Util functions to load content from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ApADlmbtmU5v"
      },
      "outputs": [],
      "source": [
        "def get_files_in_dir(path):\n",
        "  \"\"\"Get complete path of the pdf files in dir\"\"\"\n",
        "  files_list = []\n",
        "\n",
        "  for file in listdir(path):\n",
        "    file_path = join(path, file)\n",
        "    if file_path.endswith(\".pdf\") and isfile(file_path):\n",
        "      files_list.append(file_path)\n",
        "\n",
        "  return files_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ha8vFvn5-Qbr"
      },
      "outputs": [],
      "source": [
        "def load_embeddings(path):\n",
        "  \"\"\"Load embeddings from jsonl file\"\"\"\n",
        "  with open(path, 'r') as json_file:\n",
        "    json_data = [json.loads(line) for line in json_file]\n",
        "\n",
        "  return json_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC4p_C7jPkpU"
      },
      "source": [
        "### Chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhfQo5zXyvE5"
      },
      "source": [
        "Simple recursive text chunking that splits text into chunks of size 1000 and an overlap of 200 tokens.\n",
        "- The chunking done here, is the most simple one and works with pdf text, i.e. pdf containing machine readable text or digital text.\n",
        "- For pdf containing images or scanned content, another layer like OCR or custom parser should be used. Same applies if other types of files like ppt, docx etc are used.\n",
        "- Other chunking strategies like context aware chunking, Semantic chunking etc.\n",
        "\n",
        "To keep things simple, the most basic of basic chunking strategies were used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEw2gD0hcvxm"
      },
      "outputs": [],
      "source": [
        "class PDFTextSplitter:\n",
        "  \"\"\"Document splitter class for pdf text\"\"\"\n",
        "\n",
        "  def __init__(self, file_uri, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"Initialize text splitter with required params\"\"\"\n",
        "    self.file_uri = file_uri\n",
        "    self.chunk_size = chunk_size\n",
        "    self.chunk_overlap = chunk_overlap\n",
        "    self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=self.chunk_size,\n",
        "        chunk_overlap=self.chunk_overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "        length_function=len\n",
        "    )\n",
        "\n",
        "  def _clean_special_chars(self, text: str):\n",
        "    \"\"\"Remove special characters/unicodes in the text\"\"\"\n",
        "    cleaned_text = text.replace(\"\\t\\n\",\"\").replace(\"\\x08\\n\",\"\").replace(\"\\xa0\",\"\").replace(\"\\t\\r\",\"\").replace(\"\\uf0b7\",\"\")\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "  def get_page_info(self, pdf_path: str):\n",
        "    \"\"\"Get full text content of pdf and page info\"\"\"\n",
        "    doc_id = str(uuid.uuid4())\n",
        "    full_text = \"\"\n",
        "    page_info = []\n",
        "\n",
        "    pdf_doc = fitz.open(pdf_path)\n",
        "\n",
        "    for page_num in range(pdf_doc.page_count):\n",
        "      page = pdf_doc[page_num]\n",
        "      text = page.get_text()\n",
        "      page_start_idx = len(full_text)\n",
        "      full_text += text\n",
        "      page_end_idx = len(full_text)\n",
        "      page_info.append({\n",
        "          \"doc_id\": doc_id,\n",
        "          \"page_id\": page_num,\n",
        "          \"page_number\": page_num + 1,\n",
        "          \"start_char_idx\": page_start_idx,\n",
        "          \"end_char_idx\": page_end_idx,\n",
        "      })\n",
        "    full_text = self._clean_special_chars(full_text)\n",
        "\n",
        "    return doc_id, full_text, page_info\n",
        "\n",
        "  def get_chunks_with_info(self, pdf_uri: str, pdf_text: str, page_info: list, doc_id: str):\n",
        "    \"\"\"Split pdf content to chunks and return metadata dict\"\"\"\n",
        "    chunks = []\n",
        "    text_chunks = self.text_splitter.split_text(pdf_text)\n",
        "\n",
        "    start_idx = 0\n",
        "    chunk_positions = []\n",
        "\n",
        "    # Find the chunk start and end index in the pdf text\n",
        "    for chunk in tqdm(text_chunks):\n",
        "      chunk_start = pdf_text.find(chunk, start_idx)\n",
        "      if chunk_start == -1:\n",
        "        continue\n",
        "\n",
        "      chunk_end = chunk_start + len(chunk)\n",
        "      chunk_positions.append((chunk_start, chunk_end))\n",
        "      start_idx = chunk_start + 1\n",
        "\n",
        "    # Identify which pages the chunk falls under, lowest and highest number of the page will be the page span\n",
        "    for i, (chunk, (start_pos, end_pos)) in enumerate(zip(text_chunks, chunk_positions)):\n",
        "      spanning_pages = []\n",
        "      for page in page_info:\n",
        "        if (start_pos < page[\"end_char_idx\"] and end_pos > page[\"start_char_idx\"]):\n",
        "          spanning_pages.append(page[\"page_number\"])\n",
        "\n",
        "      if not spanning_pages:\n",
        "        continue\n",
        "\n",
        "      chunk_data = {\n",
        "          \"doc_id\": doc_id,\n",
        "          \"chunk_id\": f\"{doc_id}/chunks/c{i}\",\n",
        "          \"content\": chunk,\n",
        "          \"page_span\": spanning_pages,\n",
        "          \"chunk_metadata\": {\n",
        "              \"start_char_idx\": start_pos,\n",
        "              \"end_char_idx\": end_pos\n",
        "          },\n",
        "          \"document_metadata\": {\n",
        "              \"url\": pdf_uri,\n",
        "              \"title\": pdf_uri.split(\"/\")[-1]\n",
        "          }\n",
        "      }\n",
        "\n",
        "      chunks.append(chunk_data)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "  def process_documents(self, file_uri: list=[]):\n",
        "    \"\"\"Process documents to chunks\"\"\"\n",
        "    if not file_uri:\n",
        "      file_uri = self.file_uri\n",
        "\n",
        "    if not isinstance(file_uri, list):\n",
        "      file_uri = [file_uri]\n",
        "\n",
        "    chunked_file_data = []\n",
        "    for pdf_path in file_uri:\n",
        "      print(f\"Processing {pdf_path}\")\n",
        "      doc_id, pdf_text, page_info = self.get_page_info(pdf_path)\n",
        "      chunks_data = self.get_chunks_with_info(pdf_path, pdf_text, page_info, doc_id)\n",
        "      chunked_file_data.extend(chunks_data)\n",
        "\n",
        "    print(f\"Chunking completed for {pdf_path}.\")\n",
        "    return chunked_file_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VepEsWRofjlW"
      },
      "outputs": [],
      "source": [
        "document_splitter = PDFTextSplitter(rag_files_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twddGb0wl16L"
      },
      "outputs": [],
      "source": [
        "all_files_list = get_files_in_dir(rag_files_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUjwG2e2k1co",
        "outputId": "02e63653-16d8-4964-9856-427e7644decb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/drive/MyDrive/GenAI_Expts/rag_datasets/Newwhitepaper_Agents2.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60/60 [00:00<00:00, 106589.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 41995.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/drive/MyDrive/GenAI_Expts/rag_datasets/Introduction_to_climate_change_FINAL_002.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:00<00:00, 34211.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/drive/MyDrive/GenAI_Expts/rag_datasets/understanding-climate-change-2008.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 77/77 [00:00<00:00, 51247.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/drive/MyDrive/GenAI_Expts/rag_datasets/Understanding_Climate_Change.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 92/92 [00:00<00:00, 55426.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/drive/MyDrive/GenAI_Expts/rag_datasets/LLM Powered Autonomous Agents _ Lil'Log.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:00<00:00, 100932.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/drive/MyDrive/GenAI_Expts/rag_datasets/20 Easy International Recipes.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 82241.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunking completed for /content/drive/MyDrive/GenAI_Expts/rag_datasets/20 Easy International Recipes.pdf.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "all_docs_chunked_data = document_splitter.process_documents(all_files_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YBGeagmLj6n0",
        "outputId": "c4f25daa-143d-4a4c-eaba-979086fbe637"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'doc_id': 'e436348e-a04d-4a66-b325-e7aca5259704',\n",
              "  'chunk_id': 'e436348e-a04d-4a66-b325-e7aca5259704/chunks/c0',\n",
              "  'content': 'Agents\\nAuthors: Julia Wiesinger, Patrick Marlow \\nand Vladimir Vuskovic\\nAgents\\n2\\nSeptember 2024\\nAcknowledgements\\nReviewers and Contributors\\nEvan Huang\\nEmily Xue\\nOlcan Sercinoglu\\nSebastian Riedel\\nSatinder Baveja\\nAntonio Gulli\\nAnant Nawalgaria\\nCurators and Editors\\nAntonio Gulli\\nAnant Nawalgaria\\nGrace Mollison \\nTechnical Writer\\nJoey Haymaker\\nDesigner\\nMichael Lanning \\nIntroduction4\\nWhat is an agent?5\\nThe model6\\nThe tools7\\nThe orchestration layer7\\nAgents vs. models8\\nCognitive architectures: How agents operate 8\\nTools: Our keys to the outside world12\\nExtensions 13\\nSample Extensions 15\\nFunctions 18\\nUse cases21\\nFunction sample code24\\nData stores27\\nImplementation and application28\\nTools recap32\\nEnhancing model performance with targeted learning33\\nAgent quick start with LangChain35\\nProduction applications with Vertex AI agents38\\nSummary40\\nEndnotes42\\nTable of contents\\nAgents\\n4\\nSeptember 2024\\nIntroduction\\nHumans are fantastic at messy pattern recognition tasks. However, they often rely on tools',\n",
              "  'page_span': [1, 2, 3, 4],\n",
              "  'chunk_metadata': {'start_char_idx': 0, 'end_char_idx': 996},\n",
              "  'document_metadata': {'url': '/content/drive/MyDrive/GenAI_Expts/rag_datasets/Newwhitepaper_Agents2.pdf',\n",
              "   'title': 'Newwhitepaper_Agents2.pdf'}},\n",
              " {'doc_id': 'e436348e-a04d-4a66-b325-e7aca5259704',\n",
              "  'chunk_id': 'e436348e-a04d-4a66-b325-e7aca5259704/chunks/c1',\n",
              "  'content': \"Summary40\\nEndnotes42\\nTable of contents\\nAgents\\n4\\nSeptember 2024\\nIntroduction\\nHumans are fantastic at messy pattern recognition tasks. However, they often rely on tools \\n- like books, Google Search, or a calculator - to supplement their prior knowledge before \\narriving at a conclusion. Just like humans, Generative AI models can be trained to use tools \\nto access real-time information or suggest a real-world action. For example, a model can \\nleverage a database retrieval tool to access specific information, like a customer's purchase \\nhistory, so it can generate tailored shopping recommendations. Alternatively, based on a \\nuser's query, a model can make various API calls to send an email response to a colleague \\nor complete a financial transaction on your behalf. To do so, the model must not only have \\naccess to a set of external tools, it needs the ability to plan and execute any task in a self-\\ndirected fashion. This combination of reasoning, logic, and access to external information\",\n",
              "  'page_span': [3, 4],\n",
              "  'chunk_metadata': {'start_char_idx': 830, 'end_char_idx': 1827},\n",
              "  'document_metadata': {'url': '/content/drive/MyDrive/GenAI_Expts/rag_datasets/Newwhitepaper_Agents2.pdf',\n",
              "   'title': 'Newwhitepaper_Agents2.pdf'}}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Seeing the chunk content\n",
        "all_docs_chunked_data[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hSIWMP2Pm3n"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk1OzYWrCEZy"
      },
      "source": [
        "Local models\n",
        "- all-MiniLM-L6-v2 - faster and mostly accurate\n",
        "- all-mpnet-base-v2 - slightly better accuracy but slower\n",
        "\n",
        "API\n",
        "- Google, OpenAI, Above models with HF Token.\n",
        "\n",
        "Local models are difficult to run with current specs of my system, since the goal was to run this as an application. So only option is to use APIs, Google's embedding models as they are free and superior and get's the job done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EGwt_n-ynaPv"
      },
      "outputs": [],
      "source": [
        "class EmbeddingClient:\n",
        "  \"\"\"Custom class for embedding data with Gemini models\"\"\"\n",
        "  def __init__(self, model_name: str=\"models/text-embedding-004\", embedding_api_key: str=\"\"):\n",
        "    \"\"\"Initialize embedding client with required params\"\"\"\n",
        "    self.model_name = model_name\n",
        "    self.embedding_api_key = embedding_api_key\n",
        "    self.embedding_instance = GoogleGenerativeAIEmbeddings(model=self.model_name,\n",
        "                                                           google_api_key=self.embedding_api_key)\n",
        "\n",
        "  @sleep_and_retry\n",
        "  @limits(calls=120, period=60)\n",
        "  def _generate_embedding(self, chunk_content):\n",
        "    \"\"\"Helper function to generate embedding with rate limiting\"\"\"\n",
        "    try:\n",
        "      return self.embedding_instance.embed_query(chunk_content)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "  def generate_embeddings(self, chunks_data):\n",
        "    \"\"\"Generate embeddings for content\"\"\"\n",
        "\n",
        "    embeddings_data = copy.deepcopy(chunks_data)\n",
        "\n",
        "    for chunk in tqdm(embeddings_data):\n",
        "      chunk_content = chunk[\"content\"]\n",
        "      chunk_embedding = chunk_embedding = self._generate_embedding(chunk_content)\n",
        "      chunk[\"chunk_embedding\"] = chunk_embedding\n",
        "\n",
        "    return embeddings_data\n",
        "\n",
        "  def get_query_embeddings(self, content: str):\n",
        "    \"\"\"Generate embeddings for query during runtime\"\"\"\n",
        "\n",
        "    query_embedding = self.embedding_instance.embed_query(text=content)\n",
        "\n",
        "    return query_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "74b9ZUzeoykE"
      },
      "outputs": [],
      "source": [
        "embedding_instance = EmbeddingClient(embedding_api_key=GEMINI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjEdQ7w8pj6C",
        "outputId": "b70ffb81-e885-43e5-a695-fbcd1871c88a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 332/332 [02:11<00:00,  2.53it/s]\n"
          ]
        }
      ],
      "source": [
        "embeddings_data = embedding_instance.generate_embeddings(all_docs_chunked_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpSnuaeHytl8"
      },
      "outputs": [],
      "source": [
        "with open('cleaned_embeddings.jsonl', 'w') as outfile:\n",
        "  for entry in embeddings_data:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a422iax-Pqx4"
      },
      "source": [
        "### Indexing data to VectorDB\n",
        "Embeddings can be loaded from the above process or directly from the drive.\n",
        "\n",
        "For experimentation, once the embeddings are created they are stored as jsonl file and saved in drive. The file can be loaded from next time to avoid chunking and embedding again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_W9i1Ln_-fJg"
      },
      "outputs": [],
      "source": [
        "embedding_data = load_embeddings(embeddings_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf8ZaU0a_7Ly",
        "outputId": "68da1c7f-8513-4d1f-bd21-3e60a3d980b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['doc_id', 'chunk_id', 'content', 'page_span', 'chunk_metadata', 'document_metadata', 'chunk_embedding'])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_data[0].keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ve-FbxwwoqX"
      },
      "source": [
        "Milvus is a vector database know for it's speed and features. Some of the reasons for choosing Milvus over other vectore databases like ChromaDB,Qdrant etc are,\n",
        "- Getting familiar with production grade vector db. Although chromdb is simple and light, milvus is used in a lot of production projects. Mostly for it's scalability and features.\n",
        "- Metadata filtering and parsing - Milvus has better features when it comes to this.\n",
        "- Typical curiosity to use milvus, since i've experimented with chromadb and other vector db before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6xM_-U4CGFlh"
      },
      "outputs": [],
      "source": [
        "class CustomMilvusClient:\n",
        "  \"\"\"Custom class for Milvus Client to create, update and query a milvus collection\"\"\"\n",
        "  def __init__(self, uri: str):\n",
        "    self.uri = uri\n",
        "    self.milvus_client = MilvusClient(uri=self.uri)\n",
        "\n",
        "  def create_collection(self, collection_name: str=\"\", embedding_dimension: int=0, vector_field_name: str=\"\", primary_field_name: str=\"\", max_id_length: int=50):\n",
        "    \"\"\"Create collection with given fields into milvus vector db\"\"\"\n",
        "    if self.milvus_client.has_collection(collection_name):\n",
        "      print(f\"Collection with {collection_name} already exists. Over writing existing collection.\")\n",
        "      self.milvus_client.drop_collection(collection_name)\n",
        "\n",
        "    try:\n",
        "      self.milvus_client.create_collection(collection_name=collection_name,\n",
        "                                          dimension=embedding_dimension,\n",
        "                                          vector_field_name=vector_field_name,\n",
        "                                          metric_type=\"COSINE\",\n",
        "                                          primary_field_name=primary_field_name,\n",
        "                                          id_type=\"string\",\n",
        "                                          max_length=max_id_length)\n",
        "      print(f\"Collection '{collection_name}' successfully created.\")\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "  def insert_data_to_collection(self, collection_name: str=\"\", data: list=[]):\n",
        "    \"\"\"Insert data into created collection in milvus db\"\"\"\n",
        "    if self.milvus_client.has_collection(collection_name):\n",
        "      self.milvus_client.insert(collection_name=collection_name,\n",
        "                         data=data)\n",
        "      print(f\"Data successfully inserted to collection '{collection_name}'.\")\n",
        "    else:\n",
        "      raise ValueError(f\"Collection with name '{collection_name}' does not exist. Please insert into another or create a new collection using .create_collection.\")\n",
        "\n",
        "  def query_collection(self, collection_name: str=\"\", query_embedding: list=[], limit: int=5, output_fields: list=[]):\n",
        "    \"\"\"Get relevant docs based on similarity between query embedding and vectors in DB\"\"\"\n",
        "    start_time = time.time()\n",
        "    if self.milvus_client.has_collection(collection_name):\n",
        "      retriever_result = self.milvus_client.search(collection_name=collection_name,\n",
        "                                            data=[query_embedding],\n",
        "                                            limit=limit,\n",
        "                                            output_fields=output_fields)\n",
        "      end_time = time.time()\n",
        "      execution_time = end_time - start_time\n",
        "      print(f\"Retrieved in {execution_time:.6f}s.\")\n",
        "      return retriever_result\n",
        "    else:\n",
        "      raise ValueError(f\"Collection with {collection_name} does not exist. Please query on another collection or create a new collection using .create_collection.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FfWcjKYFriRG"
      },
      "outputs": [],
      "source": [
        "retriever_instance = CustomMilvusClient(uri=\"./my_milvus.db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi7528zsIm-6",
        "outputId": "a682786f-601f-4585-cdb5-2f0228612b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection 'pdfrag' successfully created.\n"
          ]
        }
      ],
      "source": [
        "retriever_instance.create_collection(collection_name=\"pdfrag\",\n",
        "                                     embedding_dimension=768,\n",
        "                                     vector_field_name=\"chunk_embedding\",\n",
        "                                     primary_field_name=\"chunk_id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tt0zz_XJXyU",
        "outputId": "6985205a-ce29-40ed-b44c-ad43c7811e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data successfully inserted to collection 'pdfrag'.\n"
          ]
        }
      ],
      "source": [
        "retriever_instance.insert_data_to_collection(collection_name=\"pdfrag\",\n",
        "                                             data=embedding_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcqhSmBG8GhH"
      },
      "source": [
        "### RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEyo5vzBg4Ab"
      },
      "source": [
        "#### Retriever Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zsEkK44yIiKq"
      },
      "outputs": [],
      "source": [
        "# Initalize retriever and embedding clients to use at runtime\n",
        "retriever_instance = CustomMilvusClient(uri=\"./my_milvus.db\")\n",
        "embedding_instance = EmbeddingClient(embedding_api_key=GEMINI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BL1zjylW5r3Y"
      },
      "outputs": [],
      "source": [
        "def get_relevant_docs(collection_name: str, query: str, top_n: int=5):\n",
        "  \"\"\"Get relevant docs for a given query\"\"\"\n",
        "  query_embedding = embedding_instance.get_query_embeddings(content=query)\n",
        "\n",
        "  docs = retriever_instance.query_collection(collection_name=\"pdfrag\",\n",
        "                                             query_embedding=query_embedding,\n",
        "                                             limit=top_n,\n",
        "                                             output_fields=[\"content\", \"page_span\",\"document_metadata\"])\n",
        "\n",
        "  return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "B5c8CYHDJvab"
      },
      "outputs": [],
      "source": [
        "query = \"Type of memory in agents?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbjZ0mnTyKOD",
        "outputId": "de17bb66-23ee-4775-878f-44c141a9d31e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved in 0.167698s.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'id': 'd07b7f7d-40e7-4aaa-999f-c9d512146bf1/chunks/c14',\n",
              "  'distance': 0.6619677543640137,\n",
              "  'entity': {'content': 'experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\nSensory memory as learning embedding representations for raw inputs, including text,\\nimage or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the\\nfinite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time,\\naccessible via fast retrieval.\\nMaximum Inner Product Search (MIPS)\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is\\nto save the embedding representation of information into a vector store database that can',\n",
              "   'page_span': [7, 8],\n",
              "   'document_metadata': {'url': \"/content/drive/MyDrive/GenAI_Expts/rag_datasets/LLM Powered Autonomous Agents _ Lil'Log.pdf\",\n",
              "    'title': \"LLM Powered Autonomous Agents _ Lil'Log.pdf\"}}},\n",
              " {'id': 'd07b7f7d-40e7-4aaa-999f-c9d512146bf1/chunks/c1',\n",
              "  'distance': 0.6501352190971375,\n",
              "  'entity': {'content': 'Reflection and refinement: The agent can do self-criticism and self-reflection over past\\nactions, learn from mistakes and refine them for future steps, thereby improving the\\nquality of final results.\\nMemory\\nShort-term memory: I would consider all the in-context learning (See Prompt\\nEngineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall\\n(infinite) information over extended periods, often by leveraging an external vector store\\nand fast retrieval.\\nTool use\\nThe agent learns to call external APIs for extra information that is missing from the model\\nweights (often hard to change after pre-training), including current information, code\\nexecution capability, access to proprietary information sources and more.\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and\\nplan ahead.',\n",
              "   'page_span': [1, 2],\n",
              "   'document_metadata': {'url': \"/content/drive/MyDrive/GenAI_Expts/rag_datasets/LLM Powered Autonomous Agents _ Lil'Log.pdf\",\n",
              "    'title': \"LLM Powered Autonomous Agents _ Lil'Log.pdf\"}}},\n",
              " {'id': 'd07b7f7d-40e7-4aaa-999f-c9d512146bf1/chunks/c12',\n",
              "  'distance': 0.6440081596374512,\n",
              "  'entity': {'content': 'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that\\nrequire memory and exploration. Only binary reward is assigned. The source\\npolicies are trained with A3C for \"dark\" environments and DQN for\\nwatermaze.\\n(Image source: Laskin et al. 2023)\\nComponent Two: Memory\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human\\nbrain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve\\ninformation. There are several types of memory in human brains.\\n1. Sensory Memory: This is the earliest stage of memory, providing the ability to retain\\nimpressions of sensory information (visual, auditory, etc) after the original stimuli have\\nended. Sensory memory typically only lasts for up to a few seconds. Subcategories include\\niconic memory (visual), echoic memory (auditory), and haptic memory (touch).',\n",
              "   'page_span': [6, 7],\n",
              "   'document_metadata': {'url': \"/content/drive/MyDrive/GenAI_Expts/rag_datasets/LLM Powered Autonomous Agents _ Lil'Log.pdf\",\n",
              "    'title': \"LLM Powered Autonomous Agents _ Lil'Log.pdf\"}}},\n",
              " {'id': 'd07b7f7d-40e7-4aaa-999f-c9d512146bf1/chunks/c31',\n",
              "  'distance': 0.6372724175453186,\n",
              "  'entity': {'content': 'inspired by The Sims. Generative agents create believable simulacra of human behavior for\\ninteractive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection\\nmechanisms to enable agents to behave conditioned on past experience, as well as to interact\\nwith other agents.\\nMemory stream: is a long-term memory module (external database) that records a\\ncomprehensive list of agents’ experience in natural language.\\nEach element is an observation, an event directly provided by the agent. - Inter-agent\\ncommunication can trigger new natural language statements.\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to\\nrelevance, recency and importance.\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\nReflection mechanism: synthesizes memories into higher level inferences over time and',\n",
              "   'page_span': [15],\n",
              "   'document_metadata': {'url': \"/content/drive/MyDrive/GenAI_Expts/rag_datasets/LLM Powered Autonomous Agents _ Lil'Log.pdf\",\n",
              "    'title': \"LLM Powered Autonomous Agents _ Lil'Log.pdf\"}}},\n",
              " {'id': '51daf8d8-02f2-41a0-995c-a202f601d616/chunks/c3',\n",
              "  'distance': 0.6332048773765564,\n",
              "  'entity': {'content': 'attempts to achieve a goal by observing the world and acting upon it using the tools that it \\nhas at its disposal. Agents are autonomous and can act independently of human intervention, \\nespecially when provided with proper goals or objectives they are meant to achieve. Agents \\ncan also be proactive in their approach to reaching their goals. Even in the absence of \\nexplicit instruction sets from a human, an agent can reason about what it should do next to \\nachieve its ultimate goal. While the notion of agents in AI is quite general and powerful, this \\nwhitepaper focuses on the specific types of agents that Generative AI models are capable of \\nbuilding at the time of publication.\\nIn order to understand the inner workings of an agent, let’s first introduce the foundational \\ncomponents that drive the agent’s behavior, actions, and decision making. The combination \\nof these components can be described as a cognitive architecture, and there are many',\n",
              "   'page_span': [5],\n",
              "   'document_metadata': {'url': '/content/drive/MyDrive/GenAI_Expts/rag_datasets/Newwhitepaper_Agents2.pdf',\n",
              "    'title': 'Newwhitepaper_Agents2.pdf'}}}]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_relevant_docs(\"pdf_rag\",query)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PFkX9oWBLVq8"
      },
      "outputs": [],
      "source": [
        "def format_sources(relevant_docs: list):\n",
        "  \"\"\"Format relevant docs into consumable format by llm\"\"\"\n",
        "  sources = \"\"\n",
        "  for i, doc in enumerate(relevant_docs[0]):\n",
        "    sources += f\"<Source{i + 1}> {doc['entity']['content']} </Source{i + 1}>\\n\"\n",
        "\n",
        "  return sources\n",
        "\n",
        "def format_citations(relevant_docs: list):\n",
        "\n",
        "    citations = []\n",
        "    docs = relevant_docs[0]\n",
        "    for doc in docs:\n",
        "        citation_data = {}\n",
        "        citation_data[\"id\"] = doc[\"id\"]\n",
        "        citation_data[\"content\"] = doc[\"entity\"][\"content\"]\n",
        "        document = doc[\"entity\"][\"document_metadata\"]\n",
        "        citation_data[\"title\"] = document[\"title\"]\n",
        "        citation_data[\"url\"] = document[\"url\"] + \"#page=\" + str(min(doc[\"entity\"][\"page_span\"]))\n",
        "        citations.append(citation_data)\n",
        "\n",
        "    return citations\n",
        "\n",
        "def format_citations_to_md(citations: list):\n",
        "  \"\"\"Format citations to display\"\"\"\n",
        "  citation_str = \"\"\n",
        "  for citation in citations:\n",
        "    citation_str += f\"[{citation['title']}]({citation['url']})<br>\"\n",
        "\n",
        "  return citation_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "aU6jArLrMtj5",
        "outputId": "f072103f-1fa8-413c-80b8-9cdac12b4631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved in 0.004101s.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<Source1> 1. Chilli con Carne \\n  \\n \\n \\nThis  was  one  of  the  first  easy \\nrecipes I learnt to cook and can be \\nmastered in just a few attempts! It’s \\nhealthy, cheap and tasty and makes \\nthe ultimate student food. You can \\nmake a large batch of this and then \\nstore in the fridge for days or freeze \\nfor weeks. \\n \\n \\nIngredients \\nGround/minced beef 500g \\n1 Large onion chopped \\n2-\\xad‐3 Cloves of Garlic \\n1-\\xad‐2 Tins of chopped tomatoes 400g \\nSqueeze of tomato puree \\n1 teaspoon of chilli powder (or to taste) \\n1 teaspoon of ground cumin \\ndash of Worcester sauce \\nSprinkle of salt and pepper \\n1 Chopped red pepper \\n1 tin of drained kidney beans 400g \\n \\nMethod \\n1) Fry the onion in a hot pan with oil until nearly brown then add chopped \\ngarlic \\n2) Add the mince and stir until brown -\\xad‐ drain any excess fat if desired \\n3) Add all dried spices and seasoning then reduce heat and add chopped \\ntomatoes \\n4) Stir well and add tomato puree and worcester sauce then leave to simmer </Source1>\\n<Source2> Quick and easy recipes \\n \\nStart cooking today! \\nYou can do it! \\n \\nCooking meals is much cheaper than eating outside. This is true everywhere \\nbut even more in Geneva... Take turns and cook for your roommate and your \\nfriends! You’ll save even more money – and the kitchen will probably stay \\ncleaner... \\n \\nI have selected only a few recipes from these websites: \\nhttp://www.studentrecipes.com/ \\nhttp://www.squidoo.com/studentfood#module55467342 \\n \\n \\nBon appétit! \\n \\nINDEX \\n1. Chili con carne \\n2. Beef in beer \\n3. Pad Thai Chicken \\n4. Thai Green Curry \\n5. Pineapple chicken \\n6. Vegetarian rice \\n7. Omelette \\n8. Egg fried rice \\n9. Salmon in the oven \\n10. \\nBasic pasta \\n11. \\nCarbonara al funghi \\n12. \\nSimple spaghetti bolognaise \\n13. \\nCucumber salad \\n14. \\nGoat cheese and Beetroot salad \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n1. Chilli con Carne \\n  \\n \\n \\nThis  was  one  of  the  first  easy \\nrecipes I learnt to cook and can be \\nmastered in just a few attempts! It’s \\nhealthy, cheap and tasty and makes </Source2>\\n<Source3> 3) Add all dried spices and seasoning then reduce heat and add chopped \\ntomatoes \\n4) Stir well and add tomato puree and worcester sauce then leave to simmer \\nfor about an hour (less if you’re in a rush) \\n5) Add the chopped red pepper and continue to simmer for 5 mins, then add \\nthe tin of drained kidney beans and cook for a further 5 mins. If the chilli \\nbecome to dry at any point just add a bit of water. \\nServe with rice, jacket potatoes or pasta! \\n2. Beef in Beer \\n \\nIngredients \\n500g of cheap beef pieces (stewing steak usually is cheap) \\n500 mls of real ale \\n4 large onions \\n2 fat cloves of garlic \\ntbsp of plain flour \\nMethod \\nRaw beef, roll it in the flour...fry 4-\\xad‐5 pieces at a time in a hot saucepan to \\nseal...put to one side when all done \\n \\ncut the onions into quarters...fry in the same frying pan as the beef...to soak up \\nthe juices... \\n \\nTowards the end of frying the onion (they should be nicely brown round the \\nedges) throw in the smashed up cloves of garlic. </Source3>\\n<Source4> the juices... \\n \\nTowards the end of frying the onion (they should be nicely brown round the \\nedges) throw in the smashed up cloves of garlic. \\n \\nTransfer the beef, onions, garlic to a deep casserole dish. Stir in the remaining \\nflour \\n \\npour on the bottle of beer -\\xad‐ really, it isn't going to be wasted!!! \\n \\nCover, and cook at 150 for about 2 and a half hours...will be gorgeous when it \\ncomes out, trust me...serve with mash \\n \\n3. Pad Thai Chicken \\n4 servings \\nIngredients \\nEssential items: \\nRice noodles (can use another type of noodle but read packet instructions for \\nhow to cook) \\n2 chicken breasts \\nsalt and pepper \\n3 medium red chillis (chopped) \\n3 spring onions (chopped) \\n2 eggs \\nCorriander (if I don't have any corriander i substitute for some dried mint) \\n1 tbsp lemon juice \\n1 tbsp brown sugar \\n2 cloves of garlic (minced) \\n3 tbsp of fish sauce \\n \\nThe following ingredients aren't essential but if you can afford them they taste \\nfantastic in this dish \\n60g cooked shrimp </Source4>\\n<Source5> packaging guidelines. \\n12. Simple Spaghetti Bolognaise  \\nA Classic College Recipe -\\xad‐ Simplified \\nI have tried to make this dish as simple as \\npossible, as you get better you can add more ingredients -\\xad‐ try cooking on a \\nlower heat for longer if you have the time. \\n \\nIngredients \\n500g beef mince \\n1 tbsp olive oil \\n1 onion, finely chopped \\n1 cup beef stock \\nclove of garlic \\nCarrots, mushroom and celery (optional) \\n1 tsp dried mixed or Italian-\\xad‐style herbs \\nSquirt of tomato paste \\n1 x 425g passatta or chopped tomatoes \\n \\nMethod \\nHeat oil in a heavy-\\xad‐based pan and add onion, stirring over a moderate heat for \\n1-\\xad‐2 minutes. \\n \\nAdd mince, stirring constantly until well browned. \\n \\nStir in remaining ingredients. \\n \\nCover and simmer gently for about 30 minutes, or until cooked through (if \\nusing chopped tomatoes this will take a bit longer. \\n \\nServe with your favourite spaghetti, bread and salad. \\n \\n13. Cucumber salad \\nIngredients \\n1 cucumber, sliced \\n3 tbsp sugar </Source5>\\n\""
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "format_sources(get_relevant_docs(\"pdfrag\",\"How to make chilli con carne\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIq2tXzrMx_e",
        "outputId": "4235910e-7674-4722-89e3-50cf202d099f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved in 0.003981s.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'id': '3158c1f0-40fd-4ad2-aa26-08032d4e1d17/chunks/c1',\n",
              "  'content': '1. Chilli con Carne \\n  \\n \\n \\nThis  was  one  of  the  first  easy \\nrecipes I learnt to cook and can be \\nmastered in just a few attempts! It’s \\nhealthy, cheap and tasty and makes \\nthe ultimate student food. You can \\nmake a large batch of this and then \\nstore in the fridge for days or freeze \\nfor weeks. \\n \\n \\nIngredients \\nGround/minced beef 500g \\n1 Large onion chopped \\n2-\\xad‐3 Cloves of Garlic \\n1-\\xad‐2 Tins of chopped tomatoes 400g \\nSqueeze of tomato puree \\n1 teaspoon of chilli powder (or to taste) \\n1 teaspoon of ground cumin \\ndash of Worcester sauce \\nSprinkle of salt and pepper \\n1 Chopped red pepper \\n1 tin of drained kidney beans 400g \\n \\nMethod \\n1) Fry the onion in a hot pan with oil until nearly brown then add chopped \\ngarlic \\n2) Add the mince and stir until brown -\\xad‐ drain any excess fat if desired \\n3) Add all dried spices and seasoning then reduce heat and add chopped \\ntomatoes \\n4) Stir well and add tomato puree and worcester sauce then leave to simmer',\n",
              "  'title': 'Easy_recipes.pdf',\n",
              "  'url': '/content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf#page=2'},\n",
              " {'id': '3158c1f0-40fd-4ad2-aa26-08032d4e1d17/chunks/c0',\n",
              "  'content': 'Quick and easy recipes \\n \\nStart cooking today! \\nYou can do it! \\n \\nCooking meals is much cheaper than eating outside. This is true everywhere \\nbut even more in Geneva... Take turns and cook for your roommate and your \\nfriends! You’ll save even more money – and the kitchen will probably stay \\ncleaner... \\n \\nI have selected only a few recipes from these websites: \\nhttp://www.studentrecipes.com/ \\nhttp://www.squidoo.com/studentfood#module55467342 \\n \\n \\nBon appétit! \\n \\nINDEX \\n1. Chili con carne \\n2. Beef in beer \\n3. Pad Thai Chicken \\n4. Thai Green Curry \\n5. Pineapple chicken \\n6. Vegetarian rice \\n7. Omelette \\n8. Egg fried rice \\n9. Salmon in the oven \\n10. \\nBasic pasta \\n11. \\nCarbonara al funghi \\n12. \\nSimple spaghetti bolognaise \\n13. \\nCucumber salad \\n14. \\nGoat cheese and Beetroot salad \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n1. Chilli con Carne \\n  \\n \\n \\nThis  was  one  of  the  first  easy \\nrecipes I learnt to cook and can be \\nmastered in just a few attempts! It’s \\nhealthy, cheap and tasty and makes',\n",
              "  'title': 'Easy_recipes.pdf',\n",
              "  'url': '/content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf#page=1'},\n",
              " {'id': '3158c1f0-40fd-4ad2-aa26-08032d4e1d17/chunks/c2',\n",
              "  'content': '3) Add all dried spices and seasoning then reduce heat and add chopped \\ntomatoes \\n4) Stir well and add tomato puree and worcester sauce then leave to simmer \\nfor about an hour (less if you’re in a rush) \\n5) Add the chopped red pepper and continue to simmer for 5 mins, then add \\nthe tin of drained kidney beans and cook for a further 5 mins. If the chilli \\nbecome to dry at any point just add a bit of water. \\nServe with rice, jacket potatoes or pasta! \\n2. Beef in Beer \\n \\nIngredients \\n500g of cheap beef pieces (stewing steak usually is cheap) \\n500 mls of real ale \\n4 large onions \\n2 fat cloves of garlic \\ntbsp of plain flour \\nMethod \\nRaw beef, roll it in the flour...fry 4-\\xad‐5 pieces at a time in a hot saucepan to \\nseal...put to one side when all done \\n \\ncut the onions into quarters...fry in the same frying pan as the beef...to soak up \\nthe juices... \\n \\nTowards the end of frying the onion (they should be nicely brown round the \\nedges) throw in the smashed up cloves of garlic.',\n",
              "  'title': 'Easy_recipes.pdf',\n",
              "  'url': '/content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf#page=3'},\n",
              " {'id': '3158c1f0-40fd-4ad2-aa26-08032d4e1d17/chunks/c3',\n",
              "  'content': \"the juices... \\n \\nTowards the end of frying the onion (they should be nicely brown round the \\nedges) throw in the smashed up cloves of garlic. \\n \\nTransfer the beef, onions, garlic to a deep casserole dish. Stir in the remaining \\nflour \\n \\npour on the bottle of beer -\\xad‐ really, it isn't going to be wasted!!! \\n \\nCover, and cook at 150 for about 2 and a half hours...will be gorgeous when it \\ncomes out, trust me...serve with mash \\n \\n3. Pad Thai Chicken \\n4 servings \\nIngredients \\nEssential items: \\nRice noodles (can use another type of noodle but read packet instructions for \\nhow to cook) \\n2 chicken breasts \\nsalt and pepper \\n3 medium red chillis (chopped) \\n3 spring onions (chopped) \\n2 eggs \\nCorriander (if I don't have any corriander i substitute for some dried mint) \\n1 tbsp lemon juice \\n1 tbsp brown sugar \\n2 cloves of garlic (minced) \\n3 tbsp of fish sauce \\n \\nThe following ingredients aren't essential but if you can afford them they taste \\nfantastic in this dish \\n60g cooked shrimp\",\n",
              "  'title': 'Easy_recipes.pdf',\n",
              "  'url': '/content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf#page=3'},\n",
              " {'id': '3158c1f0-40fd-4ad2-aa26-08032d4e1d17/chunks/c14',\n",
              "  'content': 'packaging guidelines. \\n12. Simple Spaghetti Bolognaise  \\nA Classic College Recipe -\\xad‐ Simplified \\nI have tried to make this dish as simple as \\npossible, as you get better you can add more ingredients -\\xad‐ try cooking on a \\nlower heat for longer if you have the time. \\n \\nIngredients \\n500g beef mince \\n1 tbsp olive oil \\n1 onion, finely chopped \\n1 cup beef stock \\nclove of garlic \\nCarrots, mushroom and celery (optional) \\n1 tsp dried mixed or Italian-\\xad‐style herbs \\nSquirt of tomato paste \\n1 x 425g passatta or chopped tomatoes \\n \\nMethod \\nHeat oil in a heavy-\\xad‐based pan and add onion, stirring over a moderate heat for \\n1-\\xad‐2 minutes. \\n \\nAdd mince, stirring constantly until well browned. \\n \\nStir in remaining ingredients. \\n \\nCover and simmer gently for about 30 minutes, or until cooked through (if \\nusing chopped tomatoes this will take a bit longer. \\n \\nServe with your favourite spaghetti, bread and salad. \\n \\n13. Cucumber salad \\nIngredients \\n1 cucumber, sliced \\n3 tbsp sugar',\n",
              "  'title': 'Easy_recipes.pdf',\n",
              "  'url': '/content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf#page=9'}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "format_citations(get_relevant_docs(\"pdfrag\",\"How to make chilli con carne\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "4z4_jjj3SY_Z",
        "outputId": "fba3c604-fa03-4677-a458-465f948d5ee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved in 0.004618s.\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "[Easy_recipes.pdf](/content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf#page=2)<br>[Easy_recipes.pdf](/content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf#page=1)<br>[Easy_recipes.pdf](/content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf#page=3)<br>[Easy_recipes.pdf](/content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf#page=3)<br>[Easy_recipes.pdf](/content/drive/MyDrive/GenAI_Expts/rag_datasets/Easy_recipes.pdf#page=9)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(format_citations_to_md(format_citations(get_relevant_docs(\"pdfrag\",\"How to make chilli con carne\")))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aVT-n2Kg7bT"
      },
      "source": [
        "#### Intialize LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rqRI6mKzQFLk"
      },
      "outputs": [],
      "source": [
        "LLM_CONFIGS = {\n",
        "    \"gemini-1.5-flash\": {\n",
        "        \"model\": \"gemini-1.5-flash-002\",\n",
        "        \"max_output_tokens\": 1024,\n",
        "        \"temperature\": 0.0,\n",
        "    },\n",
        "    \"gemini-1.5-pro\": {\n",
        "        \"model\": \"gemini-1.5-pro-002\",\n",
        "        \"max_output_tokens\": 1024,\n",
        "        \"temperature\": 1.0,\n",
        "    },\n",
        "    \"gemini-2.0-flash\": {\n",
        "        \"model\": \"gemini-2.0-flash-001\",\n",
        "        \"max_output_tokens\": 1024,\n",
        "        \"temperature\": 0.0,\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RhBZAkm1vib_"
      },
      "outputs": [],
      "source": [
        "chat_model = ChatGoogleGenerativeAI(**LLM_CONFIGS[\"gemini-2.0-flash\"],google_api_key=GEMINI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJE6twGwg9-H"
      },
      "source": [
        "#### Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DChOJU5Dl3RC"
      },
      "outputs": [],
      "source": [
        "router_template = \"\"\"You are a helpful assitant whose purpose is to help users with their queries.\n",
        "Given user question and previous conversation history, utlize the appropriate tools where required to help them.\n",
        "Understand the user question and identify which tools are more suitable to help them and use it accordingly.\n",
        "\n",
        "Conversation history:\n",
        "\"\"\"\n",
        "router_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", router_template),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{user_query}\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0fyfTYcvKoEk"
      },
      "outputs": [],
      "source": [
        "rag_template = \"\"\"You are a friendly and helpful chat bot. Your role is to help users by answering questions based on the sources provided.\n",
        "Maintain a friendly and supportive tone while providing accurate and helpful responses. Utilize the provided conversation history to understand previous interactions.\n",
        "Based on the sources generate a clear answer to user's question. Avoid adding any other explanation.\n",
        "\n",
        "Sources: {sources}\n",
        "\n",
        "Conversation History:\n",
        "\"\"\"\n",
        "rag_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", rag_template),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{user_query}\"),\n",
        "])\n",
        "rag_chain = rag_prompt | chat_model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "AmJn0LyEj52T"
      },
      "outputs": [],
      "source": [
        "chitchat_template = \"\"\"You are a friendly and helpful chat bot named ash. Your role is to help users by handling simple chitchat like hi, bye, thanks etc.\n",
        "Maintain a friendly and supportive tone while providing accurate and helpful responses. Utilize the provided conversation history to understand previous interactions.\n",
        "Respond appropriately to the user message, and always assure them that you are here to help.\n",
        "\n",
        "Conversation History:\n",
        "\"\"\"\n",
        "chitchat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", chitchat_template),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{user_query}\"),\n",
        "])\n",
        "chitchat_chain = chitchat_prompt | chat_model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-g7DD64vBy_"
      },
      "outputs": [],
      "source": [
        "# Prompt for rewriting query based on previous history\n",
        "# Prompt can be improved\n",
        "query_rewrite_template = \"\"\"Given the following conversation history and user followup question, rephrase the user query to be a standalone question.\n",
        "The rephrased question should be understood without the chat history and should be meaningful and complete on its own.\n",
        "Make sure that the rephrased question has all the details to be complete on it's own.\n",
        "\n",
        "If the query is independent and is not related to the chat history, then return it as is without modifications. In any other case, rephrase the query.\n",
        "If the followup is not a question, but a statement, then return it as is without modifications.\n",
        "Avoid generating a response to the followup, your role is only to rephrase the input based on history.\n",
        "\n",
        "Chat history:\n",
        "\"\"\"\n",
        "query_rewrite_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", query_rewrite_template),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"Followup message: {question}. Rephrased version:\"),\n",
        "])\n",
        "rewrite_chain = query_rewrite_prompt | chat_model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4b57rA4nv8z"
      },
      "source": [
        "#### Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oYtNd_wlmE98"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_relevant_docs_tool(query: str) -> list:\n",
        "  \"\"\"Utilize this function if user asks any questions related to climate change, recipes and LLMs terminology.\n",
        "  This tool searches and return information about recipes, LLM terminology and climate change.\n",
        "  For all user questions, utlize this tool to get relevant sources for answering user query.\n",
        "  Args:\n",
        "      query: The exact question asked by the user without any modifications\n",
        "  \"\"\"\n",
        "  print(\"---CALL RETRIEVER--\")\n",
        "  collection_name = \"pdfrag\"\n",
        "  relevant_docs = get_relevant_docs(collection_name=collection_name,\n",
        "                                    query=query)\n",
        "  # reranking logic etc can be added\n",
        "\n",
        "  return relevant_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MUP7g2ZtmE6v"
      },
      "outputs": [],
      "source": [
        "tools = [get_relevant_docs_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1w_jS4bBmE4q"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "\n",
        "  messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "  chat_messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "  chat_history: Sequence[BaseMessage]\n",
        "  relevant_docs: List\n",
        "  tool_call: dict\n",
        "  bot_response: str\n",
        "  rewritten_query: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WHDqrhHUmE2D"
      },
      "outputs": [],
      "source": [
        "def router(state):\n",
        "  \"\"\"Call router to decide which tool to user\"\"\"\n",
        "\n",
        "  print(\"---CALL ROUTER---\")\n",
        "\n",
        "  messages = state[\"messages\"]\n",
        "  chat_history = state[\"chat_history\"]\n",
        "  user_query = messages[0].content\n",
        "\n",
        "  model_with_tools = chat_model.bind_tools(tools)\n",
        "\n",
        "  router_chain = router_prompt | model_with_tools\n",
        "\n",
        "  response = router_chain.invoke({\n",
        "      \"chat_history\": chat_history,\n",
        "      \"user_query\": user_query\n",
        "  })\n",
        "\n",
        "  return {\n",
        "      \"messages\": [response],\n",
        "      \"chat_messages\": messages,\n",
        "      \"tool_call\": response.tool_calls,\n",
        "      \"rewritten_query\": state[\"rewritten_query\"]\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GbeKMcASnQNo"
      },
      "outputs": [],
      "source": [
        "def tool_check_condition(state):\n",
        "  print(\"---CHECK TOOL CALL---\")\n",
        "  print(state[\"tool_call\"])\n",
        "\n",
        "  if state.get(\"tool_call\"):\n",
        "    for tool_call in state.get(\"tool_call\"):\n",
        "      if tool_call.get(\"name\") == \"get_relevant_docs_tool\":\n",
        "        return \"retrieve_tool\"\n",
        "      elif tool_call.get(\"name\") == \"other_tool\":\n",
        "        #should modify graph accordingly\n",
        "        return \"other_tool\"\n",
        "  else:\n",
        "    return \"chit_chat\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "gQFb1InomEz2"
      },
      "outputs": [],
      "source": [
        "def rewrite(state):\n",
        "  \"\"\"Rewrite query\"\"\"\n",
        "\n",
        "  print(\"---CALL REWRITE---\")\n",
        "\n",
        "  messages = state[\"messages\"]\n",
        "  user_query = messages[0].content\n",
        "  rewritten_query = \"\"\n",
        "  chat_history = state[\"chat_history\"]\n",
        "\n",
        "  if chat_history:\n",
        "    print(\"---REWRITING USING HISTORY---\")\n",
        "    rewritten_query = rewrite_chain.invoke({\n",
        "        \"chat_history\": chat_history,\n",
        "        \"question\": user_query\n",
        "    })\n",
        "    print(\"---REWRITTEN QUERY---\")\n",
        "    print(rewritten_query)\n",
        "\n",
        "    return {\n",
        "        \"rewritten_query\": rewritten_query\n",
        "    }\n",
        "  else:\n",
        "    print(\"-HISTORY NOT FOUND-\")\n",
        "    return {\n",
        "        \"rewritten_query\": \"\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3dT14I1fjYAz"
      },
      "outputs": [],
      "source": [
        "def chit_chat(state):\n",
        "  \"\"\"Handle chit chat\"\"\"\n",
        "\n",
        "  print(\"---CALL CHITCHAT---\")\n",
        "  messages = state[\"messages\"]\n",
        "  chat_history = state.get(\"chat_history\")\n",
        "\n",
        "  user_query = messages[0].content\n",
        "  print(\"---QUERY---\", user_query)\n",
        "  rewritten_query = state.get(\"rewritten_query\")\n",
        "  if rewritten_query:\n",
        "    print(\"---USING REWRITTEN QUERY---\", rewritten_query)\n",
        "    user_query = rewritten_query\n",
        "\n",
        "  response = chitchat_chain.invoke({\n",
        "      \"chat_history\": chat_history,\n",
        "      \"user_query\": user_query\n",
        "  })\n",
        "\n",
        "  print(response)\n",
        "\n",
        "  return {\n",
        "      \"messages\": [AIMessage(content=response)],\n",
        "      \"chat_messages\": [AIMessage(content=response)],\n",
        "      \"bot_response\": response,\n",
        "      \"rewritten_query\": rewritten_query\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9FU1baZxm0pI"
      },
      "outputs": [],
      "source": [
        "def generate(state):\n",
        "  \"\"\"Generate response to user query based on retrieved sources\"\"\"\n",
        "\n",
        "  print(\"---CALL GENERATE---\")\n",
        "  messages = state[\"messages\"]\n",
        "  chat_history = state.get(\"chat_history\")\n",
        "  tool_response = json.loads(messages[-1].content)\n",
        "\n",
        "  user_query = messages[0].content\n",
        "  print(\"---QUERY---\", user_query)\n",
        "  rewritten_query = state.get(\"rewritten_query\")\n",
        "  if rewritten_query:\n",
        "    print(\"---USING REWRITTEN QUERY---\", rewritten_query)\n",
        "    user_query = rewritten_query\n",
        "\n",
        "  sources = format_sources(tool_response)\n",
        "\n",
        "  response = rag_chain.invoke({\n",
        "      \"sources\": sources,\n",
        "      \"user_query\": user_query,\n",
        "      \"chat_history\": chat_history\n",
        "  })\n",
        "\n",
        "  print(response)\n",
        "\n",
        "  return {\n",
        "      \"messages\": [AIMessage(content=response)],\n",
        "      \"chat_messages\": [AIMessage(content=response)],\n",
        "      \"relevant_docs\": format_citations(tool_response),\n",
        "      \"bot_response\": response,\n",
        "      \"rewritten_query\": rewritten_query\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27BIfiLtm0bD",
        "outputId": "1b67efb4-74bc-43df-b7ac-1678ba0c5988"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d90c55be810>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"router\", router)\n",
        "retriever = ToolNode([get_relevant_docs_tool])\n",
        "workflow.add_node(\"retriever\", retriever)\n",
        "workflow.add_node(\"rewrite\",rewrite)\n",
        "workflow.add_node(\"generate\", generate)\n",
        "workflow.add_node(\"chit_chat\",chit_chat)\n",
        "\n",
        "workflow.add_edge(START, \"rewrite\")\n",
        "workflow.add_edge(\"rewrite\", \"router\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    tool_check_condition,\n",
        "    {\n",
        "        \"retrieve_tool\": \"retriever\",\n",
        "        \"chit_chat\": \"chit_chat\"\n",
        "    }\n",
        "\n",
        ")\n",
        "workflow.add_edge(\"retriever\", \"generate\")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "workflow.add_edge(\"chit_chat\", END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "xAngqIABm0Xf",
        "outputId": "ecbd8b1c-b518-4e24-8299-9d76497fe089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\trouter(router)\n",
            "\tretriever(retriever)\n",
            "\trewrite(rewrite)\n",
            "\tgenerate(generate)\n",
            "\tchit_chat(chit_chat)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> rewrite;\n",
            "\tchit_chat --> __end__;\n",
            "\tgenerate --> __end__;\n",
            "\tretriever --> generate;\n",
            "\trewrite --> router;\n",
            "\trouter -. &nbsp;retrieve_tool&nbsp; .-> retriever;\n",
            "\trouter -.-> chit_chat;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = workflow.compile()\n",
        "print(graph.get_graph().draw_mermaid())\n",
        "Image(graph.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "23OXB2wxm0U-"
      },
      "outputs": [],
      "source": [
        "def chat_session(query, chat_history):\n",
        "  user_input = {\n",
        "      \"messages\": [\n",
        "          (\"user\", query)\n",
        "      ],\n",
        "      \"chat_history\": chat_history\n",
        "  }\n",
        "\n",
        "  graph_response = graph.invoke(user_input)\n",
        "\n",
        "  return graph_response.get(\"bot_response\"), graph_response.get(\"chat_messages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXZOdf_QnZpP",
        "outputId": "0279c66d-8eca-4f54-e392-1f28aca804c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CALL REWRITE---\n",
            "-HISTORY NOT FOUND-\n",
            "---CALL ROUTER---\n",
            "---CHECK TOOL CALL---\n",
            "[]\n",
            "---CALL CHITCHAT---\n",
            "---QUERY--- Hi\n",
            "Hi there! It's nice to chat with you. How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "response, history_0 = chat_session(\"Hi\", [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FOT5yT1nZly",
        "outputId": "4bd64c4e-61ef-4bb0-cb8c-a3c21577390f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CALL REWRITE---\n",
            "---REWRITING USING HISTORY---\n",
            "---REWRITTEN QUERY---\n",
            "How do I make chili con carne?\n",
            "---CALL ROUTER---\n",
            "---CHECK TOOL CALL---\n",
            "[{'name': 'get_relevant_docs_tool', 'args': {'query': 'chili con carne recipe'}, 'id': '777f311b-4904-4610-a351-f3b775902e19', 'type': 'tool_call'}]\n",
            "---CALL RETRIEVER--\n",
            "Retrieved in 0.003944s.\n",
            "---CALL GENERATE---\n",
            "---QUERY--- How do i make a chili con carne?\n",
            "---USING REWRITTEN QUERY--- How do I make chili con carne?\n",
            "Okay! Here are the ingredients and directions for making Chili con Carne:\n",
            "\n",
            "Ingredients:\n",
            "- Ground/minced beef 500g\n",
            "- 1 Large onion chopped\n",
            "- 2-3 Cloves of Garlic\n",
            "- 1-2 Tins of chopped tomatoes 400g\n",
            "- Squeeze of tomato puree\n",
            "- 1 teaspoon of chilli powder (or to taste)\n",
            "- 1 teaspoon of ground cumin\n",
            "- dash of Worcester sauce\n",
            "- Sprinkle of salt and pepper\n",
            "- 1 Chopped red pepper\n",
            "- 1 tin of drained kidney beans 400g\n",
            "\n",
            "Method:\n",
            "1) Fry the onion in a hot pan with oil until nearly brown then add chopped garlic\n",
            "2) Add the mince and stir until brown - drain any excess fat if desired\n",
            "3) Add all dried spices and seasoning then reduce heat and add chopped tomatoes\n",
            "4) Stir well and add tomato puree and worcester sauce then leave to simmer for about an hour (less if you’re in a rush)\n",
            "5) Add the chopped red pepper and continue to simmer for 5 mins, then add the tin of drained kidney beans and cook for a further 5 mins. If the chilli become to dry at any point just add a bit of water.\n",
            "Serve with rice, jacket potatoes or pasta!\n"
          ]
        }
      ],
      "source": [
        "followup_response, history_1 = chat_session(\"How do i make a chili con carne?\", history_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6SxL-HDnZjU",
        "outputId": "32d8948e-4a3a-4f32-cc65-f0a82e3e81ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CALL REWRITE---\n",
            "---REWRITING USING HISTORY---\n",
            "---REWRITTEN QUERY---\n",
            "How do I make a carbonara?\n",
            "---CALL ROUTER---\n",
            "---CHECK TOOL CALL---\n",
            "[{'name': 'get_relevant_docs_tool', 'args': {'query': 'how to make carbonara'}, 'id': '7d9d416b-ac38-43de-9343-123e5879363c', 'type': 'tool_call'}]\n",
            "---CALL RETRIEVER--\n",
            "Retrieved in 0.005196s.\n",
            "---CALL GENERATE---\n",
            "---QUERY--- Can you tell me how to make a carbonara\n",
            "---USING REWRITTEN QUERY--- How do I make a carbonara?\n",
            "To make Carbonara al funghi, you will need the following ingredients:\n",
            "\n",
            "- 4 x rashers streaky bacon, chopped\n",
            "- 10g dried porcini mushrooms\n",
            "- 4x closed cup mushrooms (25g each), thinly sliced\n",
            "- 90g of value spaghetti\n",
            "- 1 egg, beaten\n",
            "- 30g of Parmesan cheese, grated\n",
            "- 2 tsp olive oil\n",
            "- 1/2 x small garlic clove, finely chopped\n",
            "\n",
            "Follow these steps:\n",
            "1. Soak the porcini mushrooms in hot water for 20 minutes. Drain, chop and set aside.\n",
            "2. Mix the beaten egg and two thirds of the Parmesan cheese in a large bowl to make the Carbonara sauce. Season with salt and pepper.\n",
            "3. Cook the spaghetti according to the packet instructions.\n",
            "4. Meanwhile, heat the oil in a frying pan and fry the bacon for 3 minutes. Add the fresh mushrooms, porcini mushrooms and garlic and cook for a further 3-4 minutes, stirring frequently.\n",
            "5. Drain the spaghetti, reserving 1tbsp of the cooking water. Immediately add the pasta to the Carbonara sauce as well as the reserved cooking water, bacon and mushrooms. Toss it all together with two forks. Serve immediately topped with the remaining Parmesan cheese.\n"
          ]
        }
      ],
      "source": [
        "followup_response, history_2 = chat_session(\"Can you tell me how to make a carbonara\", history_0+history_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E1ZMbbii1ZN",
        "outputId": "a6caa9f4-5eff-478f-f704-7be9f90f41ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CALL REWRITE---\n",
            "---REWRITING USING HISTORY---\n",
            "---REWRITTEN QUERY---\n",
            "What ingredients are common between the chili con carne recipe you provided earlier and the carbonara recipe you provided earlier?\n",
            "---CALL ROUTER---\n",
            "---CHECK TOOL CALL---\n",
            "[]\n",
            "---CALL CHITCHAT---\n",
            "---QUERY--- Are there any common ingredients between the recipes?\n",
            "---USING REWRITTEN QUERY--- What ingredients are common between the chili con carne recipe you provided earlier and the carbonara recipe you provided earlier?\n",
            "Okay, let's compare the ingredients of the Chili con Carne and Carbonara recipes I provided:\n",
            "\n",
            "**Chili con Carne:**\n",
            "\n",
            "*   Ground/minced beef\n",
            "*   Onion\n",
            "*   Garlic\n",
            "*   Chopped tomatoes\n",
            "*   Tomato puree\n",
            "*   Chili powder\n",
            "*   Ground cumin\n",
            "*   Worcester sauce\n",
            "*   Salt and pepper\n",
            "*   Red pepper\n",
            "*   Kidney beans\n",
            "\n",
            "**Carbonara:**\n",
            "\n",
            "*   Streaky bacon\n",
            "*   Dried porcini mushrooms\n",
            "*   Closed cup mushrooms\n",
            "*   Spaghetti\n",
            "*   Egg\n",
            "*   Parmesan cheese\n",
            "*   Olive oil\n",
            "*   Garlic\n",
            "\n",
            "**Common Ingredients:**\n",
            "\n",
            "*   **Garlic**\n",
            "*   **Salt and pepper** (These are very common in most recipes)\n",
            "\n",
            "So, the main ingredient that both recipes share is garlic.\n"
          ]
        }
      ],
      "source": [
        "followup_response, history_3 = chat_session(\"Are there any common ingredients between the recipes?\", history_0+history_1+history_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NKx5W0hojgj",
        "outputId": "09c21080-8391-4d80-c252-46a0ac636fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CALL REWRITE---\n",
            "---REWRITING USING HISTORY---\n",
            "---REWRITTEN QUERY---\n",
            "Ok, thanks for that.\n",
            "---CALL ROUTER---\n",
            "---CHECK TOOL CALL---\n",
            "[]\n",
            "---CALL CHITCHAT---\n",
            "---QUERY--- Ok, thanks for that.\n",
            "---USING REWRITTEN QUERY--- Ok, thanks for that.\n",
            "You're welcome! I'm glad I could help. Is there anything else I can assist you with today?\n"
          ]
        }
      ],
      "source": [
        "followup_response, history_4 = chat_session(\"Ok, thanks for that.\", history_0+history_1+history_2+history_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC6ILMCWnmgJ"
      },
      "source": [
        "#### Stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "6JRMlxqqnj67"
      },
      "outputs": [],
      "source": [
        "def chat_session_stream(query, chat_history):\n",
        "    user_input = {\n",
        "        \"messages\": [\n",
        "            (\"user\", query)\n",
        "        ],\n",
        "        \"chat_history\": chat_history\n",
        "    }\n",
        "\n",
        "    graph_response = graph.stream(user_input, stream_mode=\"messages\")\n",
        "    for message_chunk, langgraph_data in graph_response:\n",
        "        print(\"--STREAM--\")\n",
        "        if langgraph_data[\"langgraph_node\"] == \"generate\":\n",
        "            yield(message_chunk.content)\n",
        "\n",
        "    return \"\", \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMzhiPDunj3Y",
        "outputId": "22283794-40f6-40eb-9e07-225415446e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CALL REWRITE---\n",
            "-HISTORY NOT FOUND-\n",
            "---CALL ROUTER---\n",
            "--STREAM--\n",
            "---CHECK TOOL CALL---\n",
            "[{'name': 'get_relevant_docs_tool', 'args': {'query': 'How do i make a chili con carne?'}, 'id': '7844b561-c265-46d9-9edb-e5ab99697dd9', 'type': 'tool_call'}]\n",
            "---CALL RETRIEVER--\n",
            "Retrieved in 0.015896s.\n",
            "--STREAM--\n",
            "---CALL GENERATE---\n",
            "---QUERY--- How do i make a chili con carne?\n",
            "--STREAM--\n",
            "To\n",
            "--STREAM--\n",
            " make Chilli con Carne, you need ground/minced beef, large onion, garlic\n",
            "--STREAM--\n",
            " cloves, chopped tomatoes, tomato puree, chilli powder, ground cumin, Worcester sauce,\n",
            "--STREAM--\n",
            " salt, pepper, chopped red pepper, and drained kidney beans. Fry the onion and garlic, add the mince until brown, drain any excess fat, add dried spices and\n",
            "--STREAM--\n",
            " seasoning, reduce heat, add chopped tomatoes, stir in tomato puree and Worcester sauce, and simmer. Add the chopped red pepper, simmer, add kidney beans, and\n",
            "--STREAM--\n",
            " cook. Serve with rice, jacket potatoes, or pasta.\n",
            "To make Chilli con Carne, you need ground/minced beef, large onion, garlic cloves, chopped tomatoes, tomato puree, chilli powder, ground cumin, Worcester sauce, salt, pepper, chopped red pepper, and drained kidney beans. Fry the onion and garlic, add the mince until brown, drain any excess fat, add dried spices and seasoning, reduce heat, add chopped tomatoes, stir in tomato puree and Worcester sauce, and simmer. Add the chopped red pepper, simmer, add kidney beans, and cook. Serve with rice, jacket potatoes, or pasta.\n",
            "--STREAM--\n",
            "To make Chilli con Carne, you need ground/minced beef, large onion, garlic cloves, chopped tomatoes, tomato puree, chilli powder, ground cumin, Worcester sauce, salt, pepper, chopped red pepper, and drained kidney beans. Fry the onion and garlic, add the mince until brown, drain any excess fat, add dried spices and seasoning, reduce heat, add chopped tomatoes, stir in tomato puree and Worcester sauce, and simmer. Add the chopped red pepper, simmer, add kidney beans, and cook. Serve with rice, jacket potatoes, or pasta.\n",
            "--STREAM--\n",
            "To make Chilli con Carne, you need ground/minced beef, large onion, garlic cloves, chopped tomatoes, tomato puree, chilli powder, ground cumin, Worcester sauce, salt, pepper, chopped red pepper, and drained kidney beans. Fry the onion and garlic, add the mince until brown, drain any excess fat, add dried spices and seasoning, reduce heat, add chopped tomatoes, stir in tomato puree and Worcester sauce, and simmer. Add the chopped red pepper, simmer, add kidney beans, and cook. Serve with rice, jacket potatoes, or pasta.\n"
          ]
        }
      ],
      "source": [
        "response = chat_session_stream(\"How do i make a chili con carne?\", [])\n",
        "for chunk in response:\n",
        "    print(chunk)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WsC0SbfTezgE",
        "ognLVOY5hNv6",
        "-sI6D1D-e14m",
        "C8C0jrH5fJPA",
        "WC4p_C7jPkpU",
        "-hSIWMP2Pm3n",
        "a422iax-Pqx4"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
