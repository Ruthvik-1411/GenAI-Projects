# Gemini Live Voice Agent Client

This is the web-based front-end client for the Gemini Live Voice Agent. It provides a user interface to capture microphone audio, stream it to the backend server via WebSockets, and play back the LLM's audio response in real-time. It also displays the conversation transcript and system logs.

## Features
- **Light weight Web UI**: A clean, light and responsive interface built with standard HTML, CSS, and JavaScript.
- **Real-time Microphone Capture**: Uses the Web Audio API and **AudioWorklets** for high-performance, non-blocking microphone recording.
- **Live Audio Playback**: Streams and plays back audio from the server with low latency, also using performant AudioWorklets.
- **Dynamic UI Updates**: The chat transcript and system logs are updated in real-time as events are received from the server.
- **Event-Driven Architecture**: Built with a modular, event-driven approach for clean and maintainable code.
- **Session Management**: Clear controls to start, stop, and reset conversation sessions.
- **Visual Feedback**: The UI provides clear visual cues for connection status and recording state.

## Architecture & Data Flow

The client application is designed around a central controller (`main.js`) that orchestrates interactions between the user interface, a dedicated WebSocket communication module (`api-client.js`), and specialized audio processing modules (AudioWorklets).

The flow for a typical interaction is as follows:

1.  **Connection:** `main.js` initializes the `ApiClient`, which establishes a WebSocket connection to the server.
2.  **Session Start:** The user clicks the "Start Session" button. `main.js` tells the `ApiClient` to send a `start_session` event to the server.
3.  **Ready Signal:** The server responds with a `status: setup_complete` event.
4.  **Audio Initialization:** Upon receiving the ready signal, `main.js` initializes the **Audio Recorder** and **Audio Player** worklets. This is a crucial step for performance, as it moves all heavy audio processing off the main browser thread.
5.  **Recording & Streaming (User -> Server):**
    -   The Audio Recorder worklet continuously captures audio from the user's microphone.
    -   It sends chunks of raw PCM audio data back to `main.js`.
    -   `main.js` passes this data to the `ApiClient`, which Base64-encodes it and sends it over the WebSocket as an `audio_chunk` event.
6.  **Receiving & Playback (Server -> User):**
    -   The `ApiClient` listens for messages from the server.
    -   When an `audio_chunk` is received, it's passed to the Audio Player worklet, which decodes it and adds it to a playback buffer for smooth, uninterrupted audio.
    -   When transcript or tool call events are received, they are used to dynamically update the chat bubbles in the UI.

This architecture ensures that the user interface remains responsive and never freezes, even while simultaneously recording and playing back audio.

## Core Components

### The User Interface (index.html)

This file defines the static structure and layout of the application. It's the "skeleton" of the UI.

-   **Layout:** It uses a simple two-column layout for the main content (chat transcript) and a sidebar (logs).
-   **Controls:** Contains the primary user controls:
    -   `startSessionButton`: To initiate a new conversation with the server.
    -   `micButton`: A multi-function button to start/stop the user's audio recording and ending the session.
    -   `newSessionButton`: To completely reset the state and start fresh.
-   **Dynamic Containers:** Includes empty `div` elements (`#log`, `#chatTranscript`) that serve as containers for the dynamic content generated by JavaScript.

### The Application Controller (main.js)

This is the "brain" of the client-side application. It listens to user actions on the UI, manages the application's state, and orchestrates the other modules.

-   **State Management:** It holds key state variables like `isRecording`, `isSessionActive`, and references to the current UI chat bubbles (`currentUserBubble`, `currentModelBubble`). This is essential for managing the flow of the conversation.
-   **DOM Manipulation:** Contains functions like `updateUserMessage` and `updateModelMessage` which are responsible for creating and updating the chat bubbles in the transcript view. The logic to append text to an existing bubble or create a new one allows for a streaming text effect.
-   **Event Handling:** The core of its logic is a series of event listeners attached to the `client` object (e.g., `client.on('user_transcript', ...)`). This ensures a clean, reactive pattern where the UI updates in response to events from the server, rather than polling for changes.
-   **Audio Orchestration:** The `initializeAudio` function is critical. It lazy-loads the AudioWorklets, ensuring they are only started when needed. The `audioRecorderHandler` function acts as a callback that is triggered by the recorder worklet every time a new chunk of audio is ready.

### The Communication Layer (api-client.js)

This module encapsulates all the logic related to WebSocket communication. It is designed to be a reusable, event-driven client.

-   By isolating the WebSocket logic here, `main.js` doesn't need to know the low-level details of the connection. It just needs to know how to send messages and listen for events. Sticking to **separation of concerns** patterns.
-   **`EventEmitter` Pattern:** The class extends `EventEmitter`. Instead of `main.js` providing callbacks to the `ApiClient`, the `ApiClient` *emits* named events (e.g., `this.emit('open')`, `this.emit('audio_chunk', ...)`). This decouples the `ApiClient` from `main.js`, making the code more modular and easier to test.
-   **Connection Management:** The `connect()` and `disconnect()` methods handle the lifecycle of the WebSocket connection, including robust error and close handling.
-   **Message Handling (`_handleMessage`):** This private method is the central point for all incoming server messages. It parses the JSON and then emits both a generic `message` event and a specific event based on the `message.event` property.
-   **Data Serialization (`sendAudio`):** This method demonstrates the client-side data preparation. It takes a raw `ArrayBuffer` of audio data, converts it to a Base64 string, and wraps it in the JSON payload structure the server expects.

### Audio Worklets (audio-player.js & audio-recorder.js)

The audio worklets play an important role in the application's performance.

-   **Why AudioWorklets?** Standard JavaScript runs on a single main thread. Heavy tasks like real-time audio encoding and decoding would block this thread, causing the UI to freeze and stutter. AudioWorklets solve this by running audio processing in a separate, high-priority thread, completely isolated from the UI.
-   **`audio-recorder.js`:** This worklet's job is to access the microphone input, process it into a standard format (16-bit PCM at 16kHz), and send the raw audio data buffers back to `main.js` via a message port.
-   **`audio-player.js`:** This worklet receives audio data buffers from `main.js`. It maintains an internal buffer to queue these chunks and schedules them for playback, ensuring a smooth, continuous audio stream without gaps or glitches, even if network packets arrive with minor jitter.

> Most of the audio processing scripts were built on top of the files here. [adk-ws-streaming-docs](https://github.com/google/adk-docs/tree/main/examples/python/snippets/streaming/adk-streaming-ws/app/static/js). Thanks to the folks who built this.

## Getting Started

### Prerequisites

-   A modern web browser that supports AudioWorklets (e.g., Chrome, Firefox, Edge).
-   The backend server must be running.

### Installation & Running

This is a static web application. It does not require a build step, but it must be served by a web server for the browser to handle JavaScript modules correctly.

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/Ruthvik-1411/GenAI-Projects
    cd GenAI-Projects/gemini_live_boilerplate/client
    ```

2.  **Serve the files:**
    The easiest way to do this is with Python's built-in HTTP server. Make sure you are in the directory containing `index.html`.

    ```bash
    python -m http.server 8080
    ```

3.  **Open in browser:**
    Navigate to `http://localhost:8080` in your web browser.

### Configuration

If your backend server is running on a different address or port, you will need to update the WebSocket URL. You can start a backend server that comes with this client, the steps to start the server can be found here: [Running the server](../server#development-guide).

1.  Open `main.js`.
2.  Find the following line at the top of the file:
    ```javascript
    const WEBSOCKET_URL = 'ws://localhost:8081/ws';
    ```
3.  Change the URL to match your server's address.